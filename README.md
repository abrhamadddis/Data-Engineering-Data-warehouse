## Week2 Data Engineering Data warehouse

## Articles
- [Medium Article] (https://medium.com/@abrhamaddis32/crafting-a-data-warehousing-infrastructure-using-postgres-dbt-and-airflow-bdd46111b374)

## Table of Contents
- [Project Structure](#project-structure)
    * [images] (#images)
    * [data](#data)
    * [models](#models)
    * [notebooks](#notebooks)
    * [DBT](#migrate_to_dbt)
    * [redash](#redash)
    * [logs](#logs)
    * [root folder](#root-folder)
  - [Installation guide](#installation-guide)
  - [Tech Stack](#tech-stack)
  - [Getting Started](#getting-started)
    * [Prerequests](*prerequests)
    * [Installations](*installations)
  - [Tech Stack](#tech-stack)

### images:

- `images/` the folder where all snapshot for the project are stored.

### logs:

- `logs/` the folder where script logs are stored.

### data:

 - `*.csv` the folder where the dataset versioned csv files are stored.

### .github:

- `.github/`: the folder where github actions and CML workflow is integrated.


### models:
- `models`: the folder where DBT model queries are stored.

### notebooks:

- `prepare.ipynb`: a jupyter notebook for exploring the data.

## Tech Stack 
Tech Stack used in this project
* [PostgreSQL](https://dev.PostgreSQL.com/doc/)
* [Apache Airflow](https://airflow.apache.org/docs/apache-airflow/stable/)
* [dbt](https://docs.getdbt.com/)
* [Redash](https://redash.io/help/)

## Contact

Abrham Addis - [@email](abrhamaddis32@gmail.com)
Contact Me  - [@contact](https://www.linkedin.com/in/abrham-addis-302748160/)
